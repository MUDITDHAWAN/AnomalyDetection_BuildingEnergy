{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "PyOD_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvVDR7QzxiWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3766fdb7-6fd8-4261-c67c-c3f417922b33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad3gOpc3SYVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "17b60228-ab8f-4932-85d4-376e530aec1a"
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyod in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Requirement already satisfied: suod in /usr/local/lib/python3.6/dist-packages (from pyod) (0.0.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pyod) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from pyod) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from pyod) (1.18.5)\n",
            "Requirement already satisfied: combo in /usr/local/lib/python3.6/dist-packages (from pyod) (0.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod) (0.48.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod) (49.2.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdvWfWGwxRXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numpy import percentile\n",
        "import sklearn\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGbwMZYsxRKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For reproducibility\n",
        "np.random.seed(12)\n",
        "tf.random.set_seed(12)\n",
        "random.seed(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnd0epiYU_Si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_saved_data = \"/content/drive/My Drive/ASHRAEData/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkgdptDh4XsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CAN BE CHANGED \n",
        "\n",
        "## change these lists as per model's input \n",
        "site_id= 0 \n",
        "\n",
        "## window length \n",
        "seq_length = 24 "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6qZ41pySdZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reading saved data Non-Anomalous\n",
        "os.chdir(dir_saved_data)\n",
        "\n",
        "## Reading training data\n",
        "with open(\"./Baseline_data/Not_Conditional/\"+ \"site_id_\" + str(site_id)+\"/non_anom/train_data.pkl\", 'rb') as f:\n",
        "  Y_train_non_anom = pickle.load(f)\n",
        "\n",
        "## Reading validation data\n",
        "with open(\"./Baseline_data/Not_Conditional/\"+ \"site_id_\" + str(site_id)+\"/non_anom/val_data.pkl\", 'rb') as f:\n",
        "  Y_val_non_anom = pickle.load(f)\n",
        "\n",
        "## Reading test data\n",
        "with open(\"./Baseline_data/Not_Conditional/\"+ \"site_id_\" + str(site_id)+\"/non_anom/test_data.pkl\", 'rb') as f:\n",
        "  Y_test_non_anom = pickle.load(f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyiiYwqMTGDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reading saved data Anomalous\n",
        "os.chdir(dir_saved_data)\n",
        "\n",
        "## Reading training data\n",
        "with open(\"./Baseline_data/Not_Conditional/\"+ \"site_id_\" + str(site_id)+\"/anom/train_data.pkl\", 'rb') as f:\n",
        "  Y_train_anom = pickle.load(f)\n",
        "\n",
        "## Reading validation data\n",
        "with open(\"./Baseline_data/Not_Conditional/\"+ \"site_id_\" + str(site_id)+\"/anom/val_data.pkl\", 'rb') as f:\n",
        "  Y_val_anom = pickle.load(f)\n",
        "\n",
        "## Reading test data\n",
        "with open(\"./Baseline_data/Not_Conditional/\"+ \"site_id_\" + str(site_id)+\"/anom/test_data.pkl\", 'rb') as f:\n",
        "  Y_test_anom = pickle.load(f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHo88wkDcsbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_pyod(Y_train_non_anom, Y_train_anom, Y_val_non_anom, Y_val_anom, Y_test_non_anom,Y_test_anom):\n",
        "  ## def to create data used for training and evaluation of BAseline PyOD models\n",
        "  \n",
        "  # Anomalous  - train data\n",
        "  arr_1 = np.zeros((1,24))\n",
        "  for i in range(len(Y_train_anom)):\n",
        "    arr_1 = np.concatenate([arr_1, Y_train_anom[i].reshape(1, 24)], axis=0)\n",
        "  arr_1 = np.delete(arr_1, (0), axis=0)\n",
        "\n",
        "  # Non- Anomalous  - train data\n",
        "  arr_0 = np.zeros((1,24))\n",
        "  for i in range(len(Y_train_non_anom)):\n",
        "    arr_0 = np.concatenate([arr_0, Y_train_non_anom[i].reshape(1, 24)], axis=0)\n",
        "  arr_0 = np.delete(arr_0, (0), axis=0)\n",
        "\n",
        "  X_train = np.concatenate([arr_0, arr_1], axis=0)\n",
        "\n",
        "  Y_train = np.zeros((arr_0.shape[0])) \n",
        "  Y_train = np.concatenate([Y_train, np.ones((arr_1.shape[0]))], axis=0)\n",
        "\n",
        "  # Anomalous  - val data\n",
        "  val_arr_1 = np.zeros((1,24))\n",
        "  for i in range(len(Y_val_anom)):\n",
        "    val_arr_1 = np.concatenate([val_arr_1, Y_val_anom[i].reshape(1, 24)], axis=0)\n",
        "  val_arr_1 = np.delete(val_arr_1, (0), axis=0)\n",
        "\n",
        "  # Non- Anomalous  - val data\n",
        "  val_arr_0 = np.zeros((1,24))\n",
        "  for i in range(len(Y_val_non_anom)):\n",
        "    val_arr_0 = np.concatenate([val_arr_0, Y_val_non_anom[i].reshape(1, 24)], axis=0)\n",
        "  val_arr_0 = np.delete(val_arr_0, (0), axis=0)\n",
        "\n",
        "  X_val = np.concatenate([val_arr_0, val_arr_1], axis=0)\n",
        "\n",
        "  Y_val = np.zeros((val_arr_0.shape[0])) \n",
        "  Y_val = np.concatenate([Y_val, np.ones((val_arr_1.shape[0]))], axis=0)\n",
        "\n",
        "\n",
        "  # Anomalous  - test data\n",
        "  test_arr_1 = np.zeros((1,24))\n",
        "  for i in range(len(Y_test_anom)):\n",
        "    test_arr_1 = np.concatenate([test_arr_1, Y_test_anom[i].reshape(1, 24)], axis=0)\n",
        "  test_arr_1 = np.delete(test_arr_1, (0), axis=0)\n",
        "\n",
        "  # Non- Anomalous  - val data\n",
        "  test_arr_0 = np.zeros((1,24))\n",
        "  for i in range(len(Y_test_non_anom)):\n",
        "    test_arr_0 = np.concatenate([test_arr_0, Y_test_non_anom[i].reshape(1, 24)], axis=0)\n",
        "  test_arr_0 = np.delete(test_arr_0, (0), axis=0)\n",
        "\n",
        "  X_test = np.concatenate([test_arr_0, test_arr_1], axis=0)\n",
        "\n",
        "  Y_test = np.zeros((test_arr_0.shape[0])) \n",
        "  Y_test = np.concatenate([Y_test, np.ones((test_arr_1.shape[0]))], axis=0)\n",
        "\n",
        "  return X_train, Y_train, X_val, Y_val, X_test, Y_test, arr_0, arr_1, val_arr_0, val_arr_1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ1JjUlwhh4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loading Dataset\n",
        "X_train, Y_train, X_val, Y_val, X_test, Y_test, arr_0, arr_1, val_arr_0, val_arr_1 = create_data_pyod(Y_train_non_anom, Y_train_anom, Y_val_non_anom, Y_val_anom, Y_test_non_anom,Y_test_anom)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3nxsBg1s83G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Shuffling the data \n",
        "x_train, y_train = shuffle(X_train, Y_train)\n",
        "x_val, y_val = shuffle(X_val, Y_val)\n",
        "x_test, y_test = shuffle(X_test, Y_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG9T24oEJ_mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# supress warnings for clean output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Import all models\n",
        "from pyod.utils import data\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.feature_bagging import FeatureBagging\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.lof import LOF\n",
        "from pyod.models.mcd import MCD\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.pca import PCA"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS7LkWyPPeKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the number of inliers and outliers training data \n",
        "training_outliers_fraction = arr_1.shape[0] / (arr_0.shape[0] + arr_1.shape[0])\n",
        "\n",
        "## Define the number of inliers and outliers validation data\n",
        "outliers_fraction = val_arr_1.shape[0] / (val_arr_0.shape[0] + val_arr_1.shape[0])\n",
        "\n",
        "\n",
        "clusters_separation = [0]\n",
        "\n",
        "# initialize a set of detectors for LSCP\n",
        "detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),\n",
        "                 LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),\n",
        "                 LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),\n",
        "                 LOF(n_neighbors=50)]\n",
        "\n",
        "random_state = 42"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uucVWEg2PW0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define outlier detection tools to be compared\n",
        "classifiers = {\n",
        "    'Cluster-based Local Outlier Factor (CBLOF)':\n",
        "        CBLOF(contamination=training_outliers_fraction,\n",
        "              check_estimator=False, random_state=random_state),\n",
        "    'Feature Bagging':\n",
        "        FeatureBagging(LOF(n_neighbors=35),\n",
        "                       contamination=training_outliers_fraction,\n",
        "                       random_state=random_state),\n",
        "    'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
        "        contamination=training_outliers_fraction),\n",
        "    'Isolation Forest': IForest(contamination=training_outliers_fraction,\n",
        "                                random_state=random_state),\n",
        "    'K Nearest Neighbors (KNN)': KNN(\n",
        "        contamination=training_outliers_fraction),\n",
        "    # 'Average KNN': KNN(method='mean',\n",
        "    #                    contamination=training_outliers_fraction),\n",
        "    # 'Median KNN': KNN(method='median',\n",
        "    #                   contamination=training_outliers_fraction),\n",
        "    'Local Outlier Factor (LOF)':\n",
        "        LOF(n_neighbors=35, contamination=training_outliers_fraction),\n",
        "    'Minimum Covariance Determinant (MCD)': MCD(\n",
        "        contamination=training_outliers_fraction, random_state=random_state),\n",
        "    'One-class SVM (OCSVM)': OCSVM(contamination=training_outliers_fraction),\n",
        "    'Principal Component Analysis (PCA)': PCA(\n",
        "        contamination=training_outliers_fraction, random_state=random_state),\n",
        "}\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RriI8mQdPYRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "dee6c890-a1f1-42d9-bac0-b9801fcc45da"
      },
      "source": [
        "# Show all detectors\n",
        "for i, clf in enumerate(classifiers.keys()):\n",
        "    print('Model', i + 1, clf)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 Cluster-based Local Outlier Factor (CBLOF)\n",
            "Model 2 Feature Bagging\n",
            "Model 3 Histogram-base Outlier Detection (HBOS)\n",
            "Model 4 Isolation Forest\n",
            "Model 5 K Nearest Neighbors (KNN)\n",
            "Model 6 Local Outlier Factor (LOF)\n",
            "Model 7 Minimum Covariance Determinant (MCD)\n",
            "Model 8 One-class SVM (OCSVM)\n",
            "Model 9 Principal Component Analysis (PCA)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEjPflykwbLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c034869d-e555-4e43-bd51-ad6b4e59fc69"
      },
      "source": [
        "## Fit the models with the generated data and\n",
        "## compare model performances\n",
        "\n",
        "## Fit the model\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "  print()\n",
        "  print(i + 1, 'fitting', clf_name)\n",
        "  # fit the train data and tag outliers\n",
        "  clf.fit(x_train)\n",
        "\n",
        "  # get the prediction labels and outlier scores of the training data\n",
        "  y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "  y_train_scores = clf.decision_scores_  # raw outlier scores\n",
        "\n",
        "  # evaluate and print the results\n",
        "  print(\"\\nOn Training Data:\")\n",
        "  data.evaluate_print(clf_name, y_train, y_train_scores)\n",
        "\n",
        "  ## VALIDATION DATA \n",
        "  # get the prediction labels and outlier scores of the validation data\n",
        "  y_val_scores = clf.decision_function(x_val)  # outlier scores\n",
        "\n",
        "  # set threshold on the validation data \n",
        "  threshold = percentile(y_val_scores, 100 * outliers_fraction)\n",
        "  print(\"threshold : \", threshold)\n",
        "  # convet scores to label using the calculated labels \n",
        "  y_val_pred = (y_val_scores > threshold).astype('int')\n",
        "\n",
        "  # evaluate and print the results on Validation data \n",
        "  print(\"\\nOn Validation Data:\")\n",
        "  tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_val, y_val_pred).ravel()\n",
        "  p = tp/(tp+fp)\n",
        "  r = tp/(tp+fn)\n",
        "  f1 = 2*p*r/(p+r)\n",
        "  print(\"Precision : {}\".format(p))\n",
        "  print(\"Recall : {}\".format(r))\n",
        "  print(\"F1 score : {}\".format(f1))\n",
        "\n",
        "  ## TEST DATA \n",
        "  # get the prediction labels and outlier scores of the validation data\n",
        "  y_test_scores = clf.decision_function(x_test)  # outlier scores\n",
        "\n",
        "  # convet scores to label using the calculated labels  (threshold from validation data )\n",
        "  y_test_pred = (y_test_scores > threshold).astype('int')\n",
        "\n",
        "  # evaluate and print the results on Validation data \n",
        "  print(\"\\nOn Test Data:\")\n",
        "  tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, y_test_pred).ravel()\n",
        "  p = tp/(tp+fp)\n",
        "  r = tp/(tp+fn)\n",
        "  f1 = 2*p*r/(p+r)\n",
        "  print(\"Precision : {}\".format(p))\n",
        "  print(\"Recall : {}\".format(r))\n",
        "  print(\"F1 score : {}\".format(f1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1 fitting Cluster-based Local Outlier Factor (CBLOF)\n",
            "\n",
            "On Training Data:\n",
            "Cluster-based Local Outlier Factor (CBLOF) ROC:0.2584, precision @ rank n:0.1235\n",
            "threshold :  1.395656412343072\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.608433734939759\n",
            "Recall : 0.19825517993456926\n",
            "F1 score : 0.299062345780556\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8532918610679109\n",
            "Recall : 0.20519852895343763\n",
            "F1 score : 0.3308376463494297\n",
            "\n",
            "2 fitting Feature Bagging\n",
            "\n",
            "On Training Data:\n",
            "Feature Bagging ROC:0.3674, precision @ rank n:0.1327\n",
            "threshold :  1.1147436704923286\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.607764390896921\n",
            "Recall : 0.1980370774263904\n",
            "F1 score : 0.29873334430004933\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8647773279352227\n",
            "Recall : 0.199713270585302\n",
            "F1 score : 0.3244885558031193\n",
            "\n",
            "3 fitting Histogram-base Outlier Detection (HBOS)\n",
            "\n",
            "On Training Data:\n",
            "Histogram-base Outlier Detection (HBOS) ROC:0.6175, precision @ rank n:0.0677\n",
            "threshold :  45.7367826236061\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.5740236148955495\n",
            "Recall : 0.13784078516902945\n",
            "F1 score : 0.22230038691523044\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8393361581920904\n",
            "Recall : 0.14816430842111825\n",
            "F1 score : 0.2518675496688742\n",
            "\n",
            "4 fitting Isolation Forest\n",
            "\n",
            "On Training Data:\n",
            "Isolation Forest ROC:0.619, precision @ rank n:0.096\n",
            "threshold :  -0.0541385280600617\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.631336405529954\n",
            "Recall : 0.17928026172300982\n",
            "F1 score : 0.27925938508578224\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8624264499859905\n",
            "Recall : 0.19185937792183508\n",
            "F1 score : 0.3138894554354477\n",
            "\n",
            "5 fitting K Nearest Neighbors (KNN)\n",
            "\n",
            "On Training Data:\n",
            "K Nearest Neighbors (KNN) ROC:0.2457, precision @ rank n:0.1314\n",
            "threshold :  0.3602986304580408\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.6171352074966533\n",
            "Recall : 0.20109051254089422\n",
            "F1 score : 0.3033393650271426\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8582818930041153\n",
            "Recall : 0.20800349061896153\n",
            "F1 score : 0.33485525061462046\n",
            "\n",
            "6 fitting Local Outlier Factor (LOF)\n",
            "\n",
            "On Training Data:\n",
            "Local Outlier Factor (LOF) ROC:0.3713, precision @ rank n:0.1331\n",
            "threshold :  1.113388694384048\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.6050870147255689\n",
            "Recall : 0.19716466739367502\n",
            "F1 score : 0.2974173383780227\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8654367878459034\n",
            "Recall : 0.19884061584491677\n",
            "F1 score : 0.32338182371128793\n",
            "\n",
            "7 fitting Minimum Covariance Determinant (MCD)\n",
            "\n",
            "On Training Data:\n",
            "Minimum Covariance Determinant (MCD) ROC:0.2607, precision @ rank n:0.1292\n",
            "threshold :  96.33945046235391\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.6211512717536813\n",
            "Recall : 0.20239912758996728\n",
            "F1 score : 0.3053133739101826\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8543388429752066\n",
            "Recall : 0.20619584865673501\n",
            "F1 score : 0.3322119005774542\n",
            "\n",
            "8 fitting One-class SVM (OCSVM)\n",
            "\n",
            "On Training Data:\n",
            "One-class SVM (OCSVM) ROC:0.5685, precision @ rank n:0.1275\n",
            "threshold :  13.238644076567631\n",
            "\n",
            "On Validation Data:\n",
            "Precision : 0.6171352074966533\n",
            "Recall : 0.20109051254089422\n",
            "F1 score : 0.3033393650271426\n",
            "\n",
            "On Test Data:\n",
            "Precision : 0.8552861784553861\n",
            "Recall : 0.21330175154272893\n",
            "F1 score : 0.341448812612253\n",
            "\n",
            "9 fitting Principal Component Analysis (PCA)\n",
            "\n",
            "On Training Data:\n",
            "Principal Component Analysis (PCA) ROC:0.8249, precision @ rank n:0.667\n",
            "threshold :  1062561.967453175\n",
            "\n",
            "On Validation Data:\n",
            "Precision : nan\n",
            "Recall : 0.0\n",
            "F1 score : nan\n",
            "\n",
            "On Test Data:\n",
            "Precision : nan\n",
            "Recall : 0.0\n",
            "F1 score : nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08bAZp_1kViq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}