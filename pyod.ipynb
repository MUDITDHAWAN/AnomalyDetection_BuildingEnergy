{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "pyod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvVDR7QzxiWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f83e7229-efc9-4691-9484-309a70633732"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdvWfWGwxRXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHtb-3pxxRQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Anomaly detection - BuildSys2020/\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGbwMZYsxRKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For reproducibility\n",
        "np.random.seed(12)\n",
        "tf.random.set_seed(12)\n",
        "random.seed(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rb-lDwvxRDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def usable_features(df_building, features_used):  # for droping the features not to be considered in the model\n",
        "  ## df_building - pandas dataframe of the datset\n",
        "  ## features_used - features to be included in the cleaned dataset\n",
        "\n",
        "  # creating list of columns that are not used \n",
        "  col = df_building.columns\n",
        "  features_not_used = [] # store columns that won't be used\n",
        "  for x in col:\n",
        "    if x not in features_used:\n",
        "      features_not_used.append(x)\n",
        "\n",
        "  # drop the columns\n",
        "  df_building= df_building.drop(features_not_used, axis = 1) # dropping not used features \n",
        "\n",
        "  # to fill NA data we simply replace the values with 0\n",
        "  df_building = df_building.fillna(0)\n",
        "  \n",
        "  return df_building"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGiZRhVxb53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_minmax(df, col):  # function to normalize the columns \n",
        "    ## df - data frame containing the columns\n",
        "    ## columns to be normalized  \n",
        "    result = df.copy()\n",
        "    for feature_name in col:\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "\n",
        "        print(\"Feature Name : {}  :  Max Value - {} ; Min Value - {}\".format(feature_name, max_value, min_value))\n",
        "        # normalize \n",
        "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtN1AvLI2kWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_zAlgo(df, col):  # function to normalize the columns \n",
        "    ## df - data frame containing the columns\n",
        "    ## columns to be normalized  \n",
        "    result = df.copy()\n",
        "    for feature_name in col:\n",
        "        std_value = df[feature_name].std()\n",
        "        mean_value = df[feature_name].mean()\n",
        "\n",
        "        print(\"Feature Name : {}  :  Std Value - {} ; Mean Value - {}\".format(feature_name, std_value, mean_value))\n",
        "        # normalize \n",
        "        result[feature_name] = (df[feature_name] - mean_value) / std_value\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3syDC9Amxbuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_dataset_ashrae(dataset, meter_types, features_used, z_columns, minmax_columns):\n",
        "  ## meter_types - list of meters to be included \n",
        "  ## features_used - list of features to be included in the final data\n",
        "  ## z_columns - list of columns to be normalized with Z algorithm\n",
        "  ## minmax_columns - list of columns to be normalized with min-max normalization\n",
        "\n",
        "  meter_dataset = dataset.loc[dataset['meter']==0]\n",
        "  \n",
        "  # create a new column  \n",
        "  meter_dataset['meter_reading_log'] = np.log(meter_dataset['meter_reading']+1) \n",
        "\n",
        "  #convert categorical data type to int\n",
        "  meter_dataset['primary_use'] = meter_dataset['primary_use'].astype('category')\n",
        "  unique_primUse_list = list(meter_dataset.primary_use.unique())\n",
        "  unique_primUse_dict = {unique_primUse_list[i]: i for i in range(0, len(unique_primUse_list))}\n",
        "  meter_dataset['primary_use'] = meter_dataset['primary_use'].map(unique_primUse_dict).astype(int)\n",
        "\n",
        "  # remove columns that won't be included in the model's input \n",
        "  df_train = usable_features(meter_dataset, features_used)\n",
        "\n",
        "  # normalize features \n",
        "  df_train_norm1 = normalize_zAlgo(df_train, z_columns) # z-algorithm\n",
        "  df_train_norm = normalize_zAlgo(df_train_norm1, minmax_columns) # min-max scaler\n",
        "\n",
        "  print(\"df_train_norm shape {}\".format(df_train_norm.shape))\n",
        "  return df_train_norm"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKGwrhmWiLKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## creating input sequence of length - seq_length\n",
        "def create_windows(arr_data, arr_anomaly_label, arr_op, seq_length, nb_features):\n",
        "  ## arr_data - normalized dataset as a numpy array \n",
        "  ## arr_op - array containing anomaly labels for each time step \n",
        "  ## seq_length - wiindow length \n",
        "  ## nb_features - no. of features to be used as input \n",
        "\n",
        "  anom_x = [] # storing anomalous windows - input \n",
        "  non_anom_x = [] # storing non-anomalous windows - input \n",
        "  anom_y = [] # storing anomalous windows - output \n",
        "  non_anom_y = [] # storing non-anomalous windows - output \n",
        "\n",
        "  # run a loop to move a seq_length size window across data non-overlapping\n",
        "  for i in range(0,arr_data.shape[0]//seq_length):\n",
        "\n",
        "    # slice the window \n",
        "    window_features = arr_data[i*seq_length:(i+1)*seq_length].reshape((seq_length, nb_features))   # window of seq_length\n",
        "    window_output = arr_op[i*seq_length:(i+1)*seq_length].reshape((seq_length,1))\n",
        "\n",
        "    is_anomaly = np.count_nonzero(arr_anomaly_label[i*seq_length:(i+1)*seq_length])  #if even at one time point anomaly is present the window would be considered anomalous\n",
        "    # print(is_anomaly)\n",
        "\n",
        "    if is_anomaly > 0 :  # separating the anomalous and non-anomalous data \n",
        "      anom_x.append(window_features)\n",
        "      anom_y.append(window_output)\n",
        "    else:\n",
        "      non_anom_x.append(window_features)\n",
        "      non_anom_y.append(window_output)\n",
        "\n",
        "  return non_anom_x, non_anom_y, anom_x, anom_y "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7HUnaYIxbfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mix_data(data_x, data_y):\n",
        "  #  Mix Data (to make it similar to i.i.d)\n",
        "  data_idx = np.random.permutation(len(data_x))\n",
        "\n",
        "\n",
        "  output_data_x = []  # Store shuffled data\n",
        "  output_data_y = []\n",
        "\n",
        "  for i in range(len(data_x)):\n",
        "    output_data_x.append(data_x[data_idx[i]])\n",
        "    output_data_y.append(data_y[data_idx[i]])\n",
        "\n",
        "  print(\"ouput_x shape {} , {}\".format(len(output_data_x), output_data_x[0].shape))\n",
        "  return output_data_x, output_data_y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f0BWA_XINKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('ashrae_rank1_train_clean.pkl', 'rb') as f:\n",
        "      dataset = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APqiUfxZxbTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_ashrae(dataset, meter_types, features_used, z_columns, minmax_columns, seq_length, nb_buildings, output_feature):\n",
        "  ## seq_length - window length \n",
        "  ## nb_buildings - no of buildings for the input samples \n",
        "  ## output_feature - feature that would be taken as the output to be predicted \n",
        "\n",
        "  ## import the dataset \n",
        "  \n",
        "\n",
        "  df_final_train_norm = clean_dataset_ashrae(dataset, meter_types, features_used, z_columns, minmax_columns)\n",
        "\n",
        "  # lists to store final input data  \n",
        "  anom_x = []\n",
        "  anom_y = []\n",
        "  non_anom_x = []\n",
        "  non_anom_y = []\n",
        "\n",
        "  # group data on the basis of their building_id \n",
        "  grp_data = df_final_train_norm.groupby('building_id')\n",
        "\n",
        "  # create a random list of building whose data would be considered \n",
        "  list_buildings = random.sample(list(grp_data.groups.keys()), nb_buildings)\n",
        "\n",
        "  # loop throught the building ids - segregate them into Anomalous and Non-Anomalouws windows\n",
        "  for grp_no in list_buildings:\n",
        "\n",
        "    # pick a building id whose data needs to be added into final input data\n",
        "    building_data = grp_data.get_group(grp_no)\n",
        "    #building_id is not needed anymore \n",
        "    building_data = building_data.drop('building_id', axis = 1) # dropping not used features \n",
        "\n",
        "    # separating labels from the data \n",
        "    arr_labels = building_data['is_bad_meter_reading'].to_numpy()\n",
        "    # label is not not need anymore \n",
        "    building_data = building_data.drop('is_bad_meter_reading', axis = 1) # dropping not used features \n",
        "\n",
        "    # separating output_feature from the data \n",
        "    arr_output = building_data[output_feature].to_numpy()\n",
        "    # output_feature is not not need anymore \n",
        "    building_data = building_data.drop(output_feature, axis = 1) # dropping not used features \n",
        "\n",
        "    # making sure the data is sequential \n",
        "    building_data.sort_values(\"timestamp\", axis = 0, ascending = True) \n",
        "    building_data = building_data.drop('timestamp', axis = 1) # dropping not used features \n",
        "\n",
        "    # creating numpy array of remaining features \n",
        "    building_data = building_data.to_numpy()\n",
        "\n",
        "    # creating windowed data\n",
        "    nb_features = building_data.shape[1]\n",
        "    na_x, na_y, a_x, a_y = create_windows(building_data, arr_labels, arr_output, seq_length, nb_features)\n",
        "\n",
        "    print(\" na_x - len {}, shape {} \".format(len(na_x), na_x[0].shape))\n",
        "    print(\" a_x - len {}\".format(len(a_x)))\n",
        "    # accumulating single bulding data \n",
        "    anom_x.extend(a_x)\n",
        "    anom_y.extend(a_y)\n",
        "    non_anom_x.extend(na_x)\n",
        "    non_anom_y.extend(na_y)\n",
        "\n",
        "  # making data similar to i.i.d.\n",
        "  anom_x, anom_y = mix_data(anom_x, anom_y)\n",
        "  non_anom_x, non_anom_y = mix_data(non_anom_x, non_anom_y)\n",
        "\n",
        "  return non_anom_x, non_anom_y, anom_x, anom_y "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkgdptDh4XsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## change these lists as per model's input \n",
        "meter_types = [0] \n",
        "\n",
        "features_used = ['building_id','timestamp', 'air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', \n",
        "                  'sea_level_pressure', 'wind_speed','primary_use', 'square_feet', 'year_built', 'floor_count', \n",
        "                  'hour', 'weekday', 'month', 'is_bad_meter_reading','meter_reading_log']\n",
        "\n",
        "z_columns = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_speed', \n",
        "              'square_feet', 'year_built' ]          \n",
        "\n",
        "minmax_columns = ['hour', 'month', 'weekday']\n",
        "\n",
        "seq_length = 24 \n",
        "\n",
        "\n",
        "nb_buildings = 145\n",
        "\n",
        "output_feature = 'meter_reading_log'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtFXHogzxbK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f4482e4-dd8d-472a-f926-308eed951688"
      },
      "source": [
        "non_anom_x, non_anom_y, anom_x, anom_y = load_data_ashrae(dataset, meter_types, features_used, z_columns, minmax_columns, seq_length, nb_buildings, output_feature)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Feature Name : air_temperature  :  Std Value - 10.692255020141602 ; Mean Value - 15.730816841125488\n",
            "Feature Name : cloud_coverage  :  Std Value - 125.52488356038128 ; Mean Value - 114.02984235849534\n",
            "Feature Name : dew_temperature  :  Std Value - 10.18441104888916 ; Mean Value - 8.148475646972656\n",
            "Feature Name : precip_depth_1_hr  :  Std Value - 6.967662172348021 ; Mean Value - 0.21803520629869555\n",
            "Feature Name : sea_level_pressure  :  Std Value - 18.378942489624023 ; Mean Value - 1023.1770629882812\n",
            "Feature Name : wind_speed  :  Std Value - 2.313711404800415 ; Mean Value - 3.6503612995147705\n",
            "Feature Name : square_feet  :  Std Value - 112109.99461909568 ; Mean Value - 92714.31195025914\n",
            "Feature Name : year_built  :  Std Value - 95.44950642767324 ; Mean Value - 168.47074200868758\n",
            "Feature Name : hour  :  Std Value - 6.922763943175829 ; Mean Value - 11.500643317958595\n",
            "Feature Name : month  :  Std Value - 3.4435748699115054 ; Mean Value - 6.552057846381409\n",
            "Feature Name : weekday  :  Std Value - 1.9972787897842907 ; Mean Value - 3.0075459480254807\n",
            "df_train_norm shape (12060910, 17)\n",
            " na_x - len 354, shape (24, 13) \n",
            " a_x - len 11\n",
            " na_x - len 351, shape (24, 13) \n",
            " a_x - len 13\n",
            " na_x - len 361, shape (24, 13) \n",
            " a_x - len 5\n",
            " na_x - len 353, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 357, shape (24, 13) \n",
            " a_x - len 8\n",
            " na_x - len 361, shape (24, 13) \n",
            " a_x - len 4\n",
            " na_x - len 339, shape (24, 13) \n",
            " a_x - len 26\n",
            " na_x - len 342, shape (24, 13) \n",
            " a_x - len 23\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 340, shape (24, 13) \n",
            " a_x - len 25\n",
            " na_x - len 268, shape (24, 13) \n",
            " a_x - len 9\n",
            " na_x - len 225, shape (24, 13) \n",
            " a_x - len 141\n",
            " na_x - len 252, shape (24, 13) \n",
            " a_x - len 71\n",
            " na_x - len 341, shape (24, 13) \n",
            " a_x - len 24\n",
            " na_x - len 335, shape (24, 13) \n",
            " a_x - len 30\n",
            " na_x - len 224, shape (24, 13) \n",
            " a_x - len 142\n",
            " na_x - len 343, shape (24, 13) \n",
            " a_x - len 22\n",
            " na_x - len 339, shape (24, 13) \n",
            " a_x - len 11\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 332, shape (24, 13) \n",
            " a_x - len 34\n",
            " na_x - len 339, shape (24, 13) \n",
            " a_x - len 26\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 224, shape (24, 13) \n",
            " a_x - len 142\n",
            " na_x - len 178, shape (24, 13) \n",
            " a_x - len 187\n",
            " na_x - len 225, shape (24, 13) \n",
            " a_x - len 141\n",
            " na_x - len 222, shape (24, 13) \n",
            " a_x - len 88\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 223, shape (24, 13) \n",
            " a_x - len 143\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 306, shape (24, 13) \n",
            " a_x - len 5\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 341, shape (24, 13) \n",
            " a_x - len 24\n",
            " na_x - len 224, shape (24, 13) \n",
            " a_x - len 142\n",
            " na_x - len 351, shape (24, 13) \n",
            " a_x - len 14\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 343, shape (24, 13) \n",
            " a_x - len 22\n",
            " na_x - len 352, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 338, shape (24, 13) \n",
            " a_x - len 28\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 361, shape (24, 13) \n",
            " a_x - len 5\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 140, shape (24, 13) \n",
            " a_x - len 225\n",
            " na_x - len 298, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 225, shape (24, 13) \n",
            " a_x - len 141\n",
            " na_x - len 307, shape (24, 13) \n",
            " a_x - len 33\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 341, shape (24, 13) \n",
            " a_x - len 24\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 300, shape (24, 13) \n",
            " a_x - len 66\n",
            " na_x - len 236, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 307, shape (24, 13) \n",
            " a_x - len 58\n",
            " na_x - len 245, shape (24, 13) \n",
            " a_x - len 121\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 127, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 296, shape (24, 13) \n",
            " a_x - len 70\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 310, shape (24, 13) \n",
            " a_x - len 13\n",
            " na_x - len 294, shape (24, 13) \n",
            " a_x - len 30\n",
            " na_x - len 225, shape (24, 13) \n",
            " a_x - len 141\n",
            " na_x - len 343, shape (24, 13) \n",
            " a_x - len 22\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 299, shape (24, 13) \n",
            " a_x - len 27\n",
            " na_x - len 328, shape (24, 13) \n",
            " a_x - len 19\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 330, shape (24, 13) \n",
            " a_x - len 35\n",
            " na_x - len 303, shape (24, 13) \n",
            " a_x - len 49\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 333, shape (24, 13) \n",
            " a_x - len 32\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 352, shape (24, 13) \n",
            " a_x - len 13\n",
            " na_x - len 351, shape (24, 13) \n",
            " a_x - len 9\n",
            " na_x - len 349, shape (24, 13) \n",
            " a_x - len 12\n",
            " na_x - len 225, shape (24, 13) \n",
            " a_x - len 141\n",
            " na_x - len 342, shape (24, 13) \n",
            " a_x - len 23\n",
            " na_x - len 224, shape (24, 13) \n",
            " a_x - len 142\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 335, shape (24, 13) \n",
            " a_x - len 31\n",
            " na_x - len 328, shape (24, 13) \n",
            " a_x - len 38\n",
            " na_x - len 354, shape (24, 13) \n",
            " a_x - len 11\n",
            " na_x - len 104, shape (24, 13) \n",
            " a_x - len 247\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 307, shape (24, 13) \n",
            " a_x - len 57\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 224, shape (24, 13) \n",
            " a_x - len 142\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 361, shape (24, 13) \n",
            " a_x - len 4\n",
            " na_x - len 355, shape (24, 13) \n",
            " a_x - len 10\n",
            " na_x - len 289, shape (24, 13) \n",
            " a_x - len 26\n",
            " na_x - len 365, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 360, shape (24, 13) \n",
            " a_x - len 6\n",
            " na_x - len 356, shape (24, 13) \n",
            " a_x - len 9\n",
            " na_x - len 305, shape (24, 13) \n",
            " a_x - len 61\n",
            " na_x - len 342, shape (24, 13) \n",
            " a_x - len 23\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 336, shape (24, 13) \n",
            " a_x - len 30\n",
            " na_x - len 221, shape (24, 13) \n",
            " a_x - len 145\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 354, shape (24, 13) \n",
            " a_x - len 11\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 1\n",
            " na_x - len 364, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 96, shape (24, 13) \n",
            " a_x - len 0\n",
            " na_x - len 344, shape (24, 13) \n",
            " a_x - len 21\n",
            " na_x - len 284, shape (24, 13) \n",
            " a_x - len 82\n",
            " na_x - len 346, shape (24, 13) \n",
            " a_x - len 13\n",
            " na_x - len 351, shape (24, 13) \n",
            " a_x - len 14\n",
            " na_x - len 362, shape (24, 13) \n",
            " a_x - len 4\n",
            " na_x - len 339, shape (24, 13) \n",
            " a_x - len 26\n",
            " na_x - len 363, shape (24, 13) \n",
            " a_x - len 2\n",
            " na_x - len 362, shape (24, 13) \n",
            " a_x - len 4\n",
            " na_x - len 97, shape (24, 13) \n",
            " a_x - len 235\n",
            " na_x - len 254, shape (24, 13) \n",
            " a_x - len 4\n",
            " na_x - len 350, shape (24, 13) \n",
            " a_x - len 16\n",
            " na_x - len 360, shape (24, 13) \n",
            " a_x - len 6\n",
            " na_x - len 224, shape (24, 13) \n",
            " a_x - len 142\n",
            " na_x - len 355, shape (24, 13) \n",
            " a_x - len 10\n",
            " na_x - len 348, shape (24, 13) \n",
            " a_x - len 17\n",
            " na_x - len 298, shape (24, 13) \n",
            " a_x - len 67\n",
            " na_x - len 301, shape (24, 13) \n",
            " a_x - len 65\n",
            " na_x - len 337, shape (24, 13) \n",
            " a_x - len 29\n",
            " na_x - len 338, shape (24, 13) \n",
            " a_x - len 27\n",
            " na_x - len 336, shape (24, 13) \n",
            " a_x - len 30\n",
            " na_x - len 225, shape (24, 13) \n",
            " a_x - len 141\n",
            " na_x - len 359, shape (24, 13) \n",
            " a_x - len 5\n",
            " na_x - len 311, shape (24, 13) \n",
            " a_x - len 0\n",
            "ouput_x shape 4859 , (24, 13)\n",
            "ouput_x shape 46182 , (24, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXEL44tMJ-WS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25687e22-343c-4188-e8f1-0bdf378226a7"
      },
      "source": [
        "len(non_anom_y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_eSygobKFSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# int((len(non_anom_y)*train_percent)) + 4796 + 4796"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jf42zRP_DPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(train_percent, val_percent, test_percent, output_non_anom_x, output_non_anom_y ):\n",
        "\n",
        "  # train dataset\n",
        "  X_train_non_anom = output_non_anom_x[:int((len(output_non_anom_y)*train_percent))]\n",
        "  Y_train_non_anom = output_non_anom_y[:int((len(output_non_anom_y)*train_percent))]\n",
        "\n",
        "  # validation dataset\n",
        "  X_val_non_anom = output_non_anom_x[int((len(output_non_anom_y)*train_percent)):-int((len(output_non_anom_y)*test_percent) )]\n",
        "  Y_val_non_anom = output_non_anom_y[int((len(output_non_anom_y)*train_percent)):-int((len(output_non_anom_y)*test_percent) )]\n",
        "\n",
        "  # test dataset                                                          \n",
        "  X_test_non_anom = output_non_anom_x[-int(len(output_non_anom_y)*test_percent):]\n",
        "  Y_test_non_anom = output_non_anom_y[-int(len(output_non_anom_y)*test_percent):]     \n",
        "\n",
        "  return  X_train_non_anom, Y_train_non_anom, X_val_non_anom, Y_val_non_anom, X_test_non_anom, Y_test_non_anom"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz3ufudCuoTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_percent = 0.8\n",
        "val_percent = 0.1\n",
        "test_percent = 0.1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GruIOx1A8fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_non_anom, Y_train_non_anom, X_val_non_anom, Y_val_non_anom, X_test_non_anom, Y_test_non_anom = split_data(train_percent, val_percent, test_percent, non_anom_x, non_anom_y)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuyAqPWmiFMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "4bf5c7a4-a31c-45b5-c7e5-0d023ee2028d"
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/4e/5767edaccbfc227914ca774cb6ca9b628a08cbb59b9b4839296953a63d34/pyod-0.8.1.tar.gz (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.5MB/s \n",
            "\u001b[?25hCollecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/2a/61b6ac584e75d8df16dc27962aa5fe99d76b09da5b6710e83d4862c84001/combo-0.1.1.tar.gz\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pyod) (0.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from pyod) (1.18.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod) (0.48.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from pyod) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyod) (1.15.0)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod) (49.1.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod) (0.31.0)\n",
            "Building wheels for collected packages: pyod, combo, suod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.1-cp36-none-any.whl size=105653 sha256=de0baeb05ca2c13fb0eb787be941a1ea4c56013760f0913ea45f8db2b55d62d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/ca/18/727e9d98a41f5f4385a97d5b429f3a9c8fbee13f9780c18642\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.1-cp36-none-any.whl size=42111 sha256=b044ec4923a49a1e96134bce8230ed35bea5fe0f980fc00b8fd65a6e4e0e7825\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/ec/e5/a2331372c676c467e70c6646e646edf6997d5c4905b8c0f5e6\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.4-cp36-none-any.whl size=2167157 sha256=51559e4b3d2ee321adeac50e58fdf38021a164716f2da8d8daf2bc0e70afcfbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/55/e5/a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
            "Successfully built pyod combo suod\n",
            "Installing collected packages: combo, suod, pyod\n",
            "Successfully installed combo-0.1.1 pyod-0.8.1 suod-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl-jdsDriIoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyod.models.knn import KNN   # kNN detector\n",
        "from pyod.utils import data"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o2ldTgdiLqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2a10638d-dcca-463e-d8e1-53f4640e3050"
      },
      "source": [
        "contamination = 0.1  # percentage of outliers\n",
        "n_train = 200  # number of training points\n",
        "n_test = 100  # number of testing points\n",
        "\n",
        "X_train, y_train, X_test, y_test = data.generate_data(\n",
        "    n_train=n_train, n_test=n_test, contamination=contamination)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyod/utils/data.py:190: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.8.0. Please use behaviour=\"new\", which makes the returned datasets in the order of X_train, X_test, y_train, y_test.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GUVd4LBiOqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f0e6a33-d529-4cea-c42b-71a0063f2a6f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGFOHbe2ip0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b55c4330-4575-4f92-fcf4-4867a6476bbc"
      },
      "source": [
        "len(Y_train_non_anom)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3NIW7jZoq8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c5d8889-80f9-472d-c422-fe225cd0861e"
      },
      "source": [
        "anom_y[0].shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHo88wkDcsbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_pyod(Y_train_non_anom, anom_y, Y_test_non_anom):\n",
        "\n",
        "  # Anomalous  - train data\n",
        "  arr_1 = np.zeros((1,24))\n",
        "  for i in range(len(anom_y)):\n",
        "    arr_1 = np.concatenate([arr_1, anom_y[i].reshape(1, 24)], axis=0)\n",
        "  arr_1 = np.delete(arr_1, (0), axis=0)\n",
        "\n",
        "  # Non- Anomalous  - train data\n",
        "  arr_0 = np.zeros((1,24))\n",
        "  for i in range(len(Y_train_non_anom)):\n",
        "    arr_0 = np.concatenate([arr_0, Y_train_non_anom[i].reshape(1, 24)], axis=0)\n",
        "  arr_0 = np.delete(arr_0, (0), axis=0)\n",
        "\n",
        "  X_train = np.concatenate([arr_0, arr_1[:4000]], axis=0)\n",
        "\n",
        "  Y_train = np.zeros((arr_0.shape[0])) \n",
        "  Y_train = np.concatenate([Y_train, np.ones((4000))], axis=0)\n",
        "\n",
        "  # Non- anomalous- test data \n",
        "  test_arr_0 = np.zeros((1,24))\n",
        "  for i in range(len(Y_test_non_anom)):\n",
        "    test_arr_0 = np.concatenate([test_arr_0, Y_test_non_anom[i].reshape(1, 24)], axis=0)\n",
        "  test_arr_0 = np.delete(test_arr_0, (0), axis=0)\n",
        "\n",
        "  # Anomalous- test data \n",
        "  X_test = np.concatenate([test_arr_0, arr_1[4000:]], axis=0)\n",
        "\n",
        "  Y_test = np.zeros((test_arr_0.shape[0]))  \n",
        "  Y_test = np.concatenate([Y_test, np.ones((len(anom_y[4000:])))], axis=0)\n",
        "\n",
        "  return X_train, Y_train, X_test, Y_test, arr_0, arr_1"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ1JjUlwhh4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train, X_test, Y_test, arr_0, arr_1 = create_data_pyod(Y_train_non_anom, anom_y, Y_test_non_anom)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3nxsBg1s83G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "x_train, y_train = shuffle(X_train, Y_train)\n",
        "x_test, y_test = shuffle(X_test, Y_test)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_UgInLotHMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "73f5eb7e-a147-4121-ea52-45cd9b5989ea"
      },
      "source": [
        "# train kNN detector\n",
        "clf_name = 'KNN'\n",
        "clf = KNN()\n",
        "clf.fit(X_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
              "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
              "  radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ws9RUVtoXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the prediction labels and outlier scores of the training data\n",
        "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "y_train_scores = clf.decision_scores_  # raw outlier scores\n",
        "\n",
        "# get the prediction on the test data\n",
        "y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
        "y_test_scores = clf.decision_function(X_test)  # outlier scores"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG9T24oEJ_mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Compare all detection algorithms \n",
        "\"\"\"\n",
        "# Author: Yue Zhao <zhaoy@cmu.edu>\n",
        "# License: BSD 2 clause\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# supress warnings for clean output\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from numpy import percentile\n",
        "\n",
        "# Import all models\n",
        "from pyod.models.abod import ABOD\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.feature_bagging import FeatureBagging\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.lof import LOF\n",
        "from pyod.models.loci import LOCI\n",
        "from pyod.models.mcd import MCD\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.pca import PCA\n",
        "from pyod.models.sos import SOS\n",
        "from pyod.models.lscp import LSCP\n",
        "from pyod.models.cof import COF\n",
        "from pyod.models.sod import SOD\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS7LkWyPPeKB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "565a5f17-29f4-440e-9324-778be5a38f84"
      },
      "source": [
        "# Define the number of inliers and outliers\n",
        "n_samples = y_train.shape[0]\n",
        "outliers_fraction = arr_1.shape[0] / arr_0.shape[0]\n",
        "\n",
        "n_inliers = arr_0.shape[0]\n",
        "n_outliers = arr_1.shape[0]\n",
        "\n",
        "ground_truth = y_train\n",
        "\n",
        "clusters_separation = [0]\n",
        "\n",
        "# initialize a set of detectors for LSCP\n",
        "detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),\n",
        "                 LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),\n",
        "                 LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),\n",
        "                 LOF(n_neighbors=50)]\n",
        "\n",
        "# Show the statics of the data\n",
        "print('Number of inliers: %i' % n_inliers)\n",
        "print('Number of outliers: %i' % n_outliers)\n",
        "print(\n",
        "    'Ground truth shape is {shape}. Outlier are 1 and inliers are 0.\\n'.format(\n",
        "        shape=ground_truth.shape))\n",
        "print(ground_truth, '\\n')\n",
        "\n",
        "random_state = 42"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of inliers: 36945\n",
            "Number of outliers: 4859\n",
            "Ground truth shape is (40945,). Outlier are 1 and inliers are 0.\n",
            "\n",
            "[0. 0. 1. ... 0. 0. 0.] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uucVWEg2PW0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define nine outlier detection tools to be compared\n",
        "classifiers = {\n",
        "    # 'Angle-based Outlier Detector (ABOD)':\n",
        "    #     ABOD(contamination=outliers_fraction),\n",
        "    'Cluster-based Local Outlier Factor (CBLOF)':\n",
        "        CBLOF(contamination=outliers_fraction,\n",
        "              check_estimator=False, random_state=random_state),\n",
        "    'Feature Bagging':\n",
        "        FeatureBagging(LOF(n_neighbors=35),\n",
        "                       contamination=outliers_fraction,\n",
        "                       random_state=random_state),\n",
        "    'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
        "        contamination=outliers_fraction),\n",
        "    'Isolation Forest': IForest(contamination=outliers_fraction,\n",
        "                                random_state=random_state),\n",
        "    'K Nearest Neighbors (KNN)': KNN(\n",
        "        contamination=outliers_fraction),\n",
        "    'Average KNN': KNN(method='mean',\n",
        "                       contamination=outliers_fraction),\n",
        "    # 'Median KNN': KNN(method='median',\n",
        "    #                   contamination=outliers_fraction),\n",
        "    'Local Outlier Factor (LOF)':\n",
        "        LOF(n_neighbors=35, contamination=outliers_fraction),\n",
        "    # 'Local Correlation Integral (LOCI)':\n",
        "    #     LOCI(contamination=outliers_fraction),\n",
        "    'Minimum Covariance Determinant (MCD)': MCD(\n",
        "        contamination=outliers_fraction, random_state=random_state),\n",
        "    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),\n",
        "    'Principal Component Analysis (PCA)': PCA(\n",
        "        contamination=outliers_fraction, random_state=random_state),\n",
        "    # 'Stochastic Outlier Selection (SOS)': SOS(\n",
        "    #     contamination=outliers_fraction),\n",
        "    # 'Locally Selective Combination (LSCP)': LSCP(\n",
        "    #     detector_list, contamination=outliers_fraction,\n",
        "    #     random_state=random_state),\n",
        "    # 'Connectivity-Based Outlier Factor (COF)':\n",
        "    #     COF(n_neighbors=35, contamination=outliers_fraction),\n",
        "    # 'Subspace Outlier Detection (SOD)':\n",
        "    #     SOD(contamination=outliers_fraction),\n",
        "}\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RriI8mQdPYRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "da7127fd-910e-4d73-dc56-2a5a53400a52"
      },
      "source": [
        "# Show all detectors\n",
        "for i, clf in enumerate(classifiers.keys()):\n",
        "    print('Model', i + 1, clf)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 Cluster-based Local Outlier Factor (CBLOF)\n",
            "Model 2 Feature Bagging\n",
            "Model 3 Histogram-base Outlier Detection (HBOS)\n",
            "Model 4 Isolation Forest\n",
            "Model 5 K Nearest Neighbors (KNN)\n",
            "Model 6 Average KNN\n",
            "Model 7 Local Outlier Factor (LOF)\n",
            "Model 8 Minimum Covariance Determinant (MCD)\n",
            "Model 9 One-class SVM (OCSVM)\n",
            "Model 10 Principal Component Analysis (PCA)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEjPflykwbLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7583ba5a-4395-4a49-ea62-0dc7c05cf7d9"
      },
      "source": [
        "# Fit the models with the generated data and\n",
        "# compare model performances\n",
        "\n",
        "# Fit the model\n",
        "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
        "    print()\n",
        "    print(i + 1, 'fitting', clf_name)\n",
        "    # fit the data and tag outliers\n",
        "    clf.fit(x_train)\n",
        "\n",
        "    # get the prediction labels and outlier scores of the training data\n",
        "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
        "\n",
        "    # get the prediction on the test data\n",
        "    y_test_pred = clf.predict(x_test)  # outlier labels (0 or 1)\n",
        "    y_test_scores = clf.decision_function(x_test)  # outlier scores\n",
        "\n",
        "\n",
        "    threshold = percentile(y_train_scores, 100 * outliers_fraction)\n",
        "\n",
        "    n_errors = (y_train_pred != ground_truth).sum()\n",
        "\n",
        "    # evaluate and print the results\n",
        "    print(\"\\nOn Training Data:\")\n",
        "    data.evaluate_print(clf_name, y_train, y_train_scores)\n",
        "    print(\"\\nOn Test Data:\")\n",
        "    data.evaluate_print(clf_name, y_test, y_test_scores)\n",
        "\n",
        "    print(\"errors on training set = \", n_errors)\n",
        "\n",
        "    print(\"threshold : \", threshold)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1 fitting Cluster-based Local Outlier Factor (CBLOF)\n",
            "\n",
            "On Training Data:\n",
            "Cluster-based Local Outlier Factor (CBLOF) ROC:0.3034, precision @ rank n:0.17\n",
            "\n",
            "On Test Data:\n",
            "Cluster-based Local Outlier Factor (CBLOF) ROC:0.3086, precision @ rank n:0.2014\n",
            "errors on training set =  7915\n",
            "threshold :  0.5208859281813201\n",
            "\n",
            "2 fitting Feature Bagging\n",
            "\n",
            "On Training Data:\n",
            "Feature Bagging ROC:0.3935, precision @ rank n:0.2228\n",
            "\n",
            "On Test Data:\n",
            "Feature Bagging ROC:0.383, precision @ rank n:0.2491\n",
            "errors on training set =  7455\n",
            "threshold :  0.9986547832010001\n",
            "\n",
            "3 fitting Histogram-base Outlier Detection (HBOS)\n",
            "\n",
            "On Training Data:\n",
            "Histogram-base Outlier Detection (HBOS) ROC:0.7524, precision @ rank n:0.0539\n",
            "\n",
            "On Test Data:\n",
            "Histogram-base Outlier Detection (HBOS) ROC:0.7672, precision @ rank n:0.0754\n",
            "errors on training set =  8040\n",
            "threshold :  32.381672173253875\n",
            "\n",
            "4 fitting Isolation Forest\n",
            "\n",
            "On Training Data:\n",
            "Isolation Forest ROC:0.7786, precision @ rank n:0.1592\n",
            "\n",
            "On Test Data:\n",
            "Isolation Forest ROC:0.7887, precision @ rank n:0.2107\n",
            "errors on training set =  7895\n",
            "threshold :  -0.11502854901644727\n",
            "\n",
            "5 fitting K Nearest Neighbors (KNN)\n",
            "\n",
            "On Training Data:\n",
            "K Nearest Neighbors (KNN) ROC:0.2789, precision @ rank n:0.222\n",
            "\n",
            "On Test Data:\n",
            "K Nearest Neighbors (KNN) ROC:0.2892, precision @ rank n:0.2549\n",
            "errors on training set =  7487\n",
            "threshold :  0.0794915003765594\n",
            "\n",
            "6 fitting Average KNN\n",
            "\n",
            "On Training Data:\n",
            "Average KNN ROC:0.2746, precision @ rank n:0.213\n",
            "\n",
            "On Test Data:\n",
            "Average KNN ROC:0.2841, precision @ rank n:0.2503\n",
            "errors on training set =  7531\n",
            "threshold :  0.06806854076608979\n",
            "\n",
            "7 fitting Local Outlier Factor (LOF)\n",
            "\n",
            "On Training Data:\n",
            "Local Outlier Factor (LOF) ROC:0.4028, precision @ rank n:0.229\n",
            "\n",
            "On Test Data:\n",
            "Local Outlier Factor (LOF) ROC:0.3932, precision @ rank n:0.248\n",
            "errors on training set =  7441\n",
            "threshold :  0.996911044027994\n",
            "\n",
            "8 fitting Minimum Covariance Determinant (MCD)\n",
            "\n",
            "On Training Data:\n",
            "Minimum Covariance Determinant (MCD) ROC:0.3495, precision @ rank n:0.2322\n",
            "\n",
            "On Test Data:\n",
            "Minimum Covariance Determinant (MCD) ROC:0.351, precision @ rank n:0.2608\n",
            "errors on training set =  7421\n",
            "threshold :  4.780768586994845\n",
            "\n",
            "9 fitting One-class SVM (OCSVM)\n",
            "\n",
            "On Training Data:\n",
            "One-class SVM (OCSVM) ROC:0.8657, precision @ rank n:0.1988\n",
            "\n",
            "On Test Data:\n",
            "One-class SVM (OCSVM) ROC:0.8727, precision @ rank n:0.2969\n",
            "errors on training set =  6912\n",
            "threshold :  -126.76807966288816\n",
            "\n",
            "10 fitting Principal Component Analysis (PCA)\n",
            "\n",
            "On Training Data:\n",
            "Principal Component Analysis (PCA) ROC:0.908, precision @ rank n:0.7552\n",
            "\n",
            "On Test Data:\n",
            "Principal Component Analysis (PCA) ROC:0.9178, precision @ rank n:0.7776\n",
            "errors on training set =  3081\n",
            "threshold :  95213.66469973476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08bAZp_1kViq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}